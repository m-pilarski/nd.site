---
title: "Entit√§tsanalyse"
subtitle: "Automatisierte Identifikation und Klassifikation von Entit√§ten und Eigennamen"
figtitle: "üè∑Ô∏è"
date: "2024-11-25T14:25:49+01:00"
toc_show: true
draft: false
html-table-processing: none
---

## Was ist Entit√§tsanalyse?

Die Entit√§tsanalyse ist eine NLP-Methode zur automatischen Erkennung und Klassifizierung wichtiger Begriffe (z.B. Personen, Orte, Organisationen) in unstrukturierten Texten. Als Entit√§t bezeichnet man dabei die Information, die aus dem Text extrahiert werden soll. Eine Entit√§t stellt dabei einen Begriff dar, der in einem Text konsequent das gleiche bezeichnet. So lassen sich mittels Entit√§tsanalyse beispielsweise Namen von Personen, Firmennamen, Orte, Ereignisse oder Zeitangaben erkennen und extrahieren. Daf√ºr sind zwei Schritte grundlegend: Die Identifikation von Entit√§ten im Text und deren Zuordnung zu vordefinierten Kategorien.

{{{< div class="grid my-4" >}}} {{{< div class="g-col-12" >}}} 

```{r}
knitr::include_graphics(here::here("content/methods/ner/img/ner.svg"))
```

{{{< /div >}}} {{{< /div >}}}

## Anwendungen

{{{< fa-ul >}}}
  {{{< fa-solid-li icon="star"  >}}} **Identifikation sensibler Informationen:** Mittels Entit√§tsanalyse lassen sich personenbezogene Daten wie Namen oder Adressen automatisch erkennen und pseudonymisieren. Ein wichtiger Schritt zur Einhaltung der DSGVO.
  {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="lightbulb"  >}}} **Wettbewerbsanalyse:** Durch das Extrahieren von Mitbewerber- oder Produktnamen lassen sich relevante Informationen f√ºr Marktanalysen gewinnen.
  {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="ticket-simple" >}}} **Dokumentenklassifikation:** Die Entit√§tsanalyse erkennt relevante Begriffe wie ‚ÄûRechnung‚Äú oder ‚ÄûProjektbericht‚Äú und unterst√ºtzt so die automatische Kategorisierung von Dokumenten. {{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}


## Ans√§tze zur Entit√§tsanalyse

F√ºr diese Methode stehen unterschiedliche Algorithmen zur Verf√ºgung, f√ºr welche Unternehmen sich entscheiden k√∂nnen, je nach ihren Bed√ºrfnissen oder verf√ºgbaren Ressourcen: 

### Regelbasierte Entit√§tsanalyse 

Regelbasierte Ans√§tze der Entit√§tsanalyse nutzen vordefinierte Muster und W√∂rterlisten, um Entit√§ten wie Personen, Organisationen oder Orte im Text zu identifizieren. Dabei werden meist zwei Verfahren kombiniert: Lexikonbasierte Erkennung und musterbasierte Regeln.

```{r}
entity_example <- 
  tibble(
  Entit√§t = c(
    "Organisation",
    "Person",
    "Ort",
    "Land",
    "Datum",
    "Uhrzeit",
    "Produkt",
    "Menge",
    "W√§hrung",
    "E-Mail"
  ),
  Beispiel = c(
    "JLU",
    "Max Msutermann",
    "Gie√üen",
    "Deutschland",
    "24.05.2024",
    "13:30",
    "Laptop",
    "20.000",
    "Euro",
    "max@mustermann.de"
  )
)


```

Beim lexikonbasierten Ansatz wird der Text mit einem vordefinierten W√∂rterverzeichnis abgeglichen, also mit Listen relevanter Namen und Begriffe. Stimmen W√∂rter im Text mit diesen Eintr√§gen √ºberein, werden sie als Entit√§t klassifiziert. Erg√§nzend kommen regelbasierte Methoden zum Einsatz, die sprachliche Strukturen analysieren. Diese Regeln basieren oft auf linguistischen Mustern, wie z.B. Gro√üschreibung innerhalb eines Satzes oder typischen Formatierungen wie Datums- oder E-Mail-Strukturen.

{{{< fa-ul >}}}
  {{{< fa-solid-li icon="thumbs-up" color="#39b185" >}}} L√§sst sich unkompliziert umsetzen, selbst mit begrenzten Ressourcen oder ohne eigene Trainingsdaten. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="thumbs-up" color="#39b185" >}}} Kann gezielt auf spezifische Anwendungsf√§lle zugeschnitten werden, etwa durch eigene Lexika oder regelbasierte Anpassungen. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="thumbs-down" color="#cf597e" >}}} Erfordert kontinuierliche Pflege, da Regeln und Lexika regelm√§√üig aktualisiert werden m√ºssen. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="thumbs-down" color="#cf597e" >}}} Die Qualit√§t h√§ngt stark von der Sprache und den verwendeten W√∂rterb√ºchern ab. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="thumbs-down" color="#cf597e" >}}} Sprachliche Varianten und Ausnahmen lassen sich nicht immer zuverl√§ssig erfassen. Dadurch k√∂nnen Entit√§ten √ºbersehen werden. {{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}

### Kontextuelle Entit√§tsanalyse

Die Entit√§tsanalyse ist ein weiterer zentraler Anwendungsfall f√ºr vortrainierte Sprachmodelle, wie bereits bei der Sentimentanalyse und Themenmodellierung gezeigt. Es stehen Modelle zur Verf√ºgung, die speziell f√ºr die Erkennung benannter Entit√§ten trainiert wurden. Alternativ k√∂nnen Unternehmen bestehende vortrainierte Modelle √ºbernehmen und mittels Fine-Tuning gezielt an ihre individuellen Anforderungen anpassen.

Besonders empfehlenswert sind Modelle aus der BERT-Familie, da sie speziell f√ºr Klassifikationsaufgaben wie die Entit√§tsanalyse konzipiert wurden und kontextuelle Informationen zuverl√§ssig verarbeiten k√∂nnen.

<!-- TODO: add cross refs  -->

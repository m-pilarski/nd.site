---
title: "Analyse von Kundenrezensionen"
subtitle: "Wie kann Kundenfeedback effektiv zur Produktoptimierung genutzt werden?"
figtitle: "⭐"
date: "2024-11-25T14:25:49+01:00"
draft: false
toc_show: true
execute: 
  echo: false
  message: false
  cache: false
---


```{r}
#| cache: false

# Setup
# Setup
set.seed(123)

library(tidyverse)
library(tidytext)
library(textdata)
library(lubridate)
library(topicmodels)
library(tm)
library(wordcloud)
library(stopwords)
library(ggplot2)


library(tidyverse)
library(gt)

tags <- htmltools::tags

calc_panel_margin_y_in <- function(.plot_obj) {
  .plot_obj <<- .plot_obj
  .plot_obj |>
    plottr::calc_element_margin_data() |>
    dplyr::filter(
      stringi::stri_detect_regex(name, "^panel(-\\d+)*$")
    ) |>
    dplyr::summarize(
      margin_top = min(plottr:::unit_to_mm(margin_top)),
      margin_bottom = min(plottr:::unit_to_mm(margin_bottom))
    ) |>
    with(unit(margin_bottom + margin_top, "mm")) |>
    grid::convertUnit("in", valueOnly = TRUE)
}

ggplot2::theme_set(`+`(
  ggplot2::theme_minimal(base_size = 14, base_family = "Open Sans"),
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(size = 12),
    axis.text.y = ggplot2::element_text(size = 12),
    axis.title.x = ggplot2::element_text(size = 14),
    axis.title.y = ggplot2::element_text(size = 14),
    title = ggplot2::element_text(size = 14),
    strip.text = ggplot2::element_text(size = 14),
    panel.grid.minor = ggplot2::element_blank(),
    panel.background = ggplot2::element_rect(fill = NA, colour = NA),
    plot.background = ggplot2::element_rect(fill = NA, colour = NA),
    legend.position = "bottom",
    legend.text = ggplot2::element_text(size = 12)
  )
))

data_dir <- here::here("content", "case_studies", "customer_reviews", "data")
```

Kundenrezensionen bieten wertvolle Einblicke in die Nutzung und Bewertung von Produkten, oft jedoch in unstrukturierter Form. Mittels Methoden der Textanalyse lassen sich diese Informationen systematisch aufbereiten und helfen, Nutzerbedürfnisse gezielt zu erkennen. Ziel dieser Case Study ist es, ein differenziertes Bild der Kundenerfahrungen mit verschiedenen technischen Produktgruppen zu zeichnen und daraus Verbesserungspotenziale abzuleiten.


### Laden des Datensatzes 

Die Analyse basiert auf 3.413 deutschsprachigen Amazon-Rezensionen, die jeweils das Datum, die Sternebewertung und den Link der Rezension enthalten. Ein Ausschnitt der ersten Beobachtungen ist in der folgenden Tabelle dargestellt. 

```{r}
reviews <-
  read_csv(fs::path(data_dir, "Amazon-Deutsch-Dataset.csv")) |>
  select(-1, -3, -author, -`web-scraper-order`, -`next`, -`Unnamed: 9`)
```

```{r}
tags <- htmltools::tags

card_test <- tags$div(
  tags$ul(
    class = "list-group list-group-flush",
    tags$li(tags$code("Datum:"), "5. Januar 2020", class = "list-group-item"),
    tags$li(
      tags$code("Inhalt:"),
      "Ich bin sehr zufrieden mit dem iPhone 11. Der Wechsel vom iPhone 6s war ein riesiger Quantensprung, der sich allerdings gelohnt hat. Ich würde es jederzeit wieder kaufen.",
      class = "list-group-item"
    ),
    tags$li(
      tags$code("Bewertung:"),
      htmltools::HTML(
        "<i class='fa-solid fa-star'></i>&nbsp;<i class='fa-solid fa-star'></i>&nbsp;<i class='fa-solid fa-star'></i>&nbsp;<i class='fa-solid fa-star'></i>&nbsp;<i class='fa-regular fa-star'></i>"
      ),
      class = "list-group-item"
    ),
    tags$li(
      tags$code("URL:"),
      tags$a(
        "https://www.amazon.de/Apple-iPhone-11-128-GB-Schwarz/product-reviews/B07XRFCP6G/ref=cm_cr_arp_d_paging_btm_10?ie=UTF8&filterByStar=positive&pageNumber=10&reviewerType=all_reviews",
        href = "https://www.amazon.de/Apple-iPhone-11-128-GB-Schwarz/product-reviews/B07XRFCP6G/ref=cm_cr_arp_d_paging_btm_10?ie=UTF8&filterByStar=positive&pageNumber=10&reviewerType=all_reviews"
      ),
      class = "list-group-item"
    ),
  ),
  class = "card" #, style="width: 100%;"
)
```

```{r}
library(htmltools)

reviews |>
  slice_sample(n = 10) |>
  mutate(
    Datum = date,
    Titel = title,
    Rezension = content,
    Bewertung = local({
      .rating_int <- as.integer(
        stringi::stri_extract_first_regex(rating, "^(\\d+)")
      )
      .stars <- purrr::map(.rating_int, \(..rating_int) {
        htmltools::tagList(
          purrr::list_flatten(rep.int(
            list(nd.util::icon_fa("fa-solid fa-star")),
            times = ..rating_int
          )),
          purrr::list_flatten(rep.int(
            list(nd.util::icon_fa("fa-regular fa-star")),
            times = 5L - ..rating_int
          )),
          sep = "",
          collapse = ""
        )
      })
      return(.stars)
    }),
    URL = map(`next-href`, \(.url) {
      tags$a(href = .url, .url)
    }),
    .keep = "none"
  ) |>
  as.list() |>
  list_transpose() |>
  map(\(.row_list) {
    tags$div(
      class = "card",
      style = "width: 100%;",
      tags$ul(
        class = "list-group list-group-flush",
        !!!unname(imap(.row_list, \(.value, .key) {
          tags$li(
            class = "list-group-item",
            tags$div(
              style = stringi::stri_c(
                "overflow: hidden; width: 100%; display: -webkit-box; ",
                "-webkit-line-clamp: 8; -webkit-box-orient: vertical;"
              ),
              tags$code(stringi::stri_c(.key, ":")),
              .value
            )
          )
        }))
      )
    )
  }) |>
  nd.util::nd_carousel(.title = "Beispielbeobachtungen aus dem Rohdatensatz")
```

```{r}
# reviews |>
#   head(1) |>
#   gt::gt() |>
#   gt::tab_header(
#     title = "Beispiel einer Beobachtung aus dem Rohdatensatz"
#   ) |>
#   gt::tab_options(
#     table.width = gt::pct(100),
#     table.font.size = gt::px(13),
#     data_row.padding = gt::px(4),
#     ihtml.use_pagination = FALSE,
#     ihtml.use_text_wrapping = TRUE
#   )

reviews <-
  reviews |>
  select(title, date, content, rating, `next-href`) |>
  mutate(
    Sprache = cld3::detect_language(content),
    Produkt = str_extract(
      `next-href`,
      "(?<=amazon\\.de/).*?(?=/product-reviews)"
    ) |>
      str_replace_all("-", " ") |>
      URLdecode(),
    Produkttyp = case_when(
      str_detect(Produkt, regex("iphone|samsung|smartphone", TRUE)) ~
        "Smartphone",
      str_detect(Produkt, regex("kopfhörer|ear", TRUE)) ~ "Kopfhörer",
      str_detect(Produkt, regex("gigaset|telefon", TRUE)) ~ "Telefonzubehör",
      TRUE ~ "Other"
    ),
    Bewertung = str_extract(rating, "^\\d+,\\d+") |>
      str_replace(",", ".") |>
      as.numeric()
  ) |>
  filter(Sprache == "de", Produkttyp != "Other") |>
  drop_na(Produkt) |>
  mutate(
    row_id = row_number(),
    .before = title
  ) |>
  rename(
    ID = row_id,
    Titel = title,
    Datum = date,
    Inhalt = content,
    URL = `next-href`
  ) |>
  select(-rating)
```


### Vorverarbeitung der Textdaten

In dieser Analyse kommen überwiegend **lexikon- und regelbasierte Verfahren** zum Einsatz, die empfindlich auf irrelevante Inhalte reagieren. Bevor sich jedoch das Signal erkennen lässt, muss das Rauschen entfernt werden.

Als erster Schritt wird der Text daher so aufbereitet, dass aus der Vielzahl an Formulierungen, Füllwörtern und inhaltsarmen Begriffen jene sprachlichen Elemente herausgefiltert werden, die einen **bedeutungsvollen Mehrwert** bieten. Dieser Prozess ist als {{{< crossref path="/basics#textdaten-für-analysen-vorbereiten" label="Vorverarbeitung" >}}} bekannt und bildet die Grundlage für konsistente und aussagekräftige Ergebnisse.

Die folgenden Schritte wurden dabei durchgeführt:


{{{< fa-ul >}}}
  {{{< fa-solid-li icon="broom" >}}} **Bereinigung der Sternebewertungen:** Bewertungsangaben im Fließtext wurden extrahiert und als numerische Werte gespeichert (z.B. „5,0 von 5 Sternen“ → 5). {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="scissors" >}}} **Tokenisierung:** Die Texte wurden in einzelne Wörter zerlegt, um eine strukturierte Analyse zu ermöglichen. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="filter" >}}}	**Stopword-Filter:** Häufige, wenig aussagekräftige Wörter (z.B. „und“, „ist“, "oder") sowie produktspezifische Begriffe wurden entfernt. {{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}

Diese Schritte gewährleisten, dass die nachfolgenden Analysen auf dem **wesentlichen Kern** der Kundenrezensionen basieren.



```{r}
# stopwords
product_terms <- reviews$Produkt |>
  str_split("\\s+") |>
  unlist() |>
  tolower() |>
  unique()

# custom_stopwords <- tibble(Wort = tolower(c(read_lines("data/german_stopwords_full.txt"), product_terms)))
custom_stopwords <- tibble(
  Wort = tolower(c(
    quanteda::stopwords(language = "de", source = "nltk"),
    product_terms
  ))
)


# tokenize and clean
review_tokens <- reviews |>
  unnest_tokens(Wort, Inhalt)

review_tokens_clean <- review_tokens |>
  filter(!str_detect(Wort, "^\\d+$|^[sa]\\d+$|^[0-9]+[a-z]*$")) |>
  anti_join(custom_stopwords, by = "Wort")


```

```{r}
reviews |>
  slice_sample(n = 10) |>
  mutate(
    Produkttyp,
    Produkt,
    Bewertung,
    Wörter = Inhalt |>
      stringi::stri_trans_tolower() |>
      stringi::stri_split_boundaries(type = "word", skip_word_none = TRUE) |>
      map_chr(\(.token) {
        .token |>
          stringi::stri_subset_regex(
            "^\\d+$|^[sa]\\d+$|^[0-9]+[a-z]*$",
            negate = TRUE
          ) |>
          setdiff(pull(custom_stopwords, Wort)) |>
          map_chr(\(..str) {
            stringi::stri_c("\"", ..str, "\"")
          }) |>
          stringi::stri_c(collapse = ", ") |>
          (\(..str) {
            stringi::stri_c("[", ..str, "]")
          })()
      }),
    .keep = "none"
  ) |>
  as.list() |>
  list_transpose() |>
  map(\(.row_list) {
    tags$div(
      class = "card",
      style = "width: 100%;",
      tags$ul(
        class = "list-group list-group-flush",
        !!!unname(imap(.row_list, \(.value, .key) {
          tags$li(
            class = "list-group-item",
            tags$div(
              style = stringi::stri_c(
                "overflow: hidden; width: 100%; display: -webkit-box; ",
                "-webkit-line-clamp: 8; -webkit-box-orient: vertical;"
              ),
              tags$code(stringi::stri_c(.key, ":")),
              .value
            )
          )
        }))
      )
    )
  }) |>
  nd.util::nd_carousel(.title = "Beispielbeobachtung nach der Vorverarbeitung")
```



### Analyse 

#### Erste Einblicke: Vergleich der Produktkategorien 

Wir beginnen mit einer rein **explorativen Betrachtung:** Gibt es Unterschiede in der durchschnittlichen Bewertung zwischen den Produktkategorien?

Dazu werden die Produktnamen aus den URLs extrahiert und manuell drei Kategorien zugeordnet: **Smartphones**, **Kopfhörer** und **Telefonzubehör.**

**Beispiel:** Aus der URL *https://www.amazon.de/sony-kopfhoerer-mdr/product-reviews/* wird „sony kopfhoerer mdr“ extrahiert und der Kategorie „Kopfhörer“ zugewiesen.


```{r}
reviews |>
  group_by(Produkttyp) |>
  summarise(avg_rating = mean(Bewertung, na.rm = TRUE)) |>
  arrange(desc(avg_rating)) |>
  gt::gt() |>
  gt::fmt_number(columns = avg_rating, decimals = 2) |>
  gt::cols_label(
    Produkttyp = "Produkttyp",
    avg_rating = "Ø Bewertung"
  ) |>
  gt::tab_options(
    table.width = gt::pct(100)
  ) |>
  nd.util::nd_gt_tab_options() |>
  nd.util::nd_gt_to_html()
```

Ein Blick auf den Durchschnitt der Bewertungen nach Produktkategorie zeigt zusätzlich Unterschiede in der Kundenzufriedenheit:

{{{< fa-ul >}}}
  {{{< fa-solid-li icon="lightbulb" >}}} Die Kategorie "Telefonzubehör" (z.B. Anrufbeantworter) schneidet im Schnitt am besten ab. {{{< /fa-solid-li >}}}
  {{{< fa-solid-li icon="lightbulb" >}}} Kopfhörer hingegen zeigen im Vergleich die niedrigsten Durchschnittsbewertungen. {{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}



#### Worthäufigkeiten 

Um ein erstes Gefühl für den Inhalt der Kundenrezensionen zu erhalten, bietet sich eine einfache **Häufigkeitsanalyse** der verwendeten Begriffe an. Die erste Grafik zeigt die häufigsten Wörter über alle Produktkategorien hinweg. Begriffe wie "super", "funktioniert" und "zufrieden" lassen bereits darauf schließen, dass Kund:innen grundsätzlich positive Erfahrungen mit den Produkten machen. Sie liefern jedoch wenig tiefergehende Erkenntnisse, da sie sehr allgemein sind.

```{r}
#| fig-height: 3.173071

# word freq
wort_plot <- review_tokens_clean |>
  count(Wort, sort = TRUE) |>
  slice_head(n = 10) |>
  ggplot(aes(x = reorder(Wort, n), y = n)) +
  geom_col(show.legend = FALSE, fill = "#837591") +
  coord_flip() +
  labs(x = "Wort", y = "Anzahl") +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  10 * 0.25 + calc_panel_margin_y_in(wort_plot)
}

wort_plot
```


Im nächsten Schritt untersuchen wir die **häufigsten Begriffe pro Kategorie**, um inhaltliche Unterschiede sichtbar zu machen.

```{r}
#| fig-height: 3.505128

produkttyp_plot <- review_tokens_clean |>
  count(Produkttyp, Wort) |>
  group_by(Produkttyp) |>
  slice_max(n, n = 10) |>
  ungroup() |>
  ggplot(aes(
    x = reorder_within(Wort, n, Produkttyp),
    y = n,
    fill = Produkttyp
  )) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Produkttyp, scales = "free") +
  scale_x_reordered() +
  rcartocolor::scale_fill_carto_d(type = "diverging", palette = "Temps") +
  coord_flip() +
  labs(x = NULL, y = "Wortanzahl") +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  10 * 0.25 + calc_panel_margin_y_in(produkttyp_plot)
}

produkttyp_plot
```


Während bei *Smartphones* und *Telefonzubehör* Begriffe wie „funktioniert“ oder „super“ dominieren, tauchen bei *Kopfhörern* vermehrt Wörter wie „kaputt“ oder „wackelkontakt“ auf. In Kombination mit der vergleichsweise niedrigen Durchschnittsbewertung deutet dies darauf hin, dass gerade bei Kopfhörern häufiger Probleme auftreten.

Häufigkeitsanalysen zeigen dominante Begriffe, vernachlässigen jedoch deren Aussagekraft pro Kategorie. Die TF-IDF-Analyse hebt hingegen kategorietypische Begriffe hervor. Die {{{< crossref path="/basics#tf-idf" label="TF-IDF-Metrik" >}}} gewichtet Wörter nicht nur nach ihrer Häufigkeit, sondern berücksichtigt auch, wie exklusiv sie für eine bestimmte Kategorie sind.


```{r}
#| fig-height: 3.831082

# TF-IDF
tfidf_plot <- review_tokens_clean |>
  count(Produkttyp, Wort) |>
  bind_tf_idf(Wort, Produkttyp, n) |>
  group_by(Produkttyp) |>
  slice_max(tf_idf, n = 10) |>
  ungroup() |>
  ggplot(aes(
    x = reorder_within(Wort, tf_idf, Produkttyp),
    y = tf_idf,
    fill = Produkttyp
  )) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Produkttyp, scales = "free") +
  scale_x_reordered() +
  scale_y_continuous(breaks = scales::pretty_breaks(3)) +
  rcartocolor::scale_fill_carto_d(type = "diverging", palette = "Temps") +
  coord_flip() +
  labs(x = NULL, y = "TF‑IDF") +
  theme(
    panel.grid.major.y = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)
  )

if (interactive()) {
  10 * 0.25 + calc_panel_margin_y_in(tfidf_plot)
}

tfidf_plot
```

In der Grafik wird deutlich:

{{{< fa-ul >}}}
  {{{< fa-solid-li icon="lightbulb" >}}} Bei *Kopfhörern* stehen „musik“, „kabelbruch“ und „enttäuschend“ für typische Nutzung und Schwächen. {{{< /fa-solid-li >}}}

  {{{< fa-solid-li icon="lightbulb" >}}} Bei *Smartphones* dominieren Themen wie „kamera“, „videos“ und „wasserdicht“. {{{< /fa-solid-li >}}}

  {{{< fa-solid-li icon="lightbulb" >}}} Die Kategorie *Telefonzubehör* ist geprägt von Begriffen wie „fritzbox“, „router“ und „reichweite“.{{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}

Dadurch lassen sich erste Hinweise auf die zentralen Themen und Probleme pro Produktkategorie identifizieren. Dies stellt einen wichtiger Schritt dar, um die Inhalte der Rezensionen gezielter auszuwerten und in späteren Analysen (z.B. Sentiment oder Themenmodellierung) weiter zu untersuchen.



#### Sentimentanalyse 

Um über reine Sternebewertungen hinauszugehen, analysieren wir den Textinhalt der Rezensionen mithilfe einer {{{< crossref path="/methods/sentiment#lexikonbasierte-sentimentanalyse" label="lexikonbasierten Sentimentanalyse" >}}}. Dabei wird jeder Rezension einen numerischen Sentimentwert zugewiesen, der positive und negative Begriffe entsprechend abbildet. 


```{r}
#| fig-height: 2

## Sentiment Analysis
sentiment_tokens <- vns::calc_tok_sentidict_tbl(
  reviews$Inhalt,
  .sentidict_tbl = vns.data::gerpolclu_tbl
)

review_sentiment <- sentiment_tokens |>
  group_by(doc_id = as.character(doc_id)) |>
  summarise(sentiment_score = sum(tok_pol_num, na.rm = TRUE), .groups = "drop")

review_summary <- reviews |>
  mutate(ID = as.character(ID)) |>
  left_join(review_sentiment, by = c("ID" = "doc_id")) |>
  mutate(sentiment_score = replace_na(sentiment_score, 0))


### Overall sentiment
sentiment_summary <- review_summary |>
  mutate(
    sentiment_class = case_when(
      sentiment_score > 0 ~ "positive",
      sentiment_score == 0 ~ "neutral",
      sentiment_score < 0 ~ "negative"
    )
  ) |>
  summarise(
    avg_sentiment_score = mean(sentiment_score),
    median_sentiment_score = median(sentiment_score),
    positive_reviews = sum(sentiment_class == "positive"),
    negative_reviews = sum(sentiment_class == "negative"),
    neutral_reviews = sum(sentiment_class == "neutral"),
    total_reviews = n()
  ) |>
  mutate(
    perc_positive = positive_reviews / total_reviews * 100,
    perc_negative = negative_reviews / total_reviews * 100,
    perc_neutral = neutral_reviews / total_reviews * 100
  )


# sentiment_summary |>
#   select(perc_positive, perc_negative, perc_neutral) |>
#   pivot_longer(everything(), names_to = "sentiment", values_to = "percent") |>
#   mutate(
#     sentiment = recode(sentiment,
#                        perc_positive = "Positiv",
#                        perc_negative = "Negativ",
#                        perc_neutral = "Neutral")
#   ) |>
#   ggplot(aes(x = "", y = percent, fill = sentiment)) +
#   geom_col(width = 0.6) +
#   coord_flip(clip = "off") +
#   geom_text(
#     aes(label = paste0(round(percent, 1), "%")),
#     position = position_stack(vjust = 0.5),
#     color = "black", size = 4
#   ) +
#   scale_fill_manual(values = c("Positiv" = "#39b185", "Negativ" = "#cf597e", "Neutral" = "#e9e29c")) +
#   scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
#   labs(y = "Anteil der Bewertungen", x = NULL) +
#   theme(
#     panel.grid.major = ggplot2::element_line(),
#     legend.title = ggplot2::element_blank(),
#     legend.text = ggplot2::element_text(size = 12)
#   )

```



```{r}
sentiment_summary_per_class <-
  review_summary |>
  mutate(
    sentiment_class = case_when(
      sentiment_score > 0 ~ "Positive",
      sentiment_score == 0 ~ "Neutral",
      sentiment_score < 0 ~ "Negative"
    )
  ) |>
  group_by(Produkttyp) |>
  summarise(
    avg_sentiment_score = mean(sentiment_score),
    median_sentiment_score = median(sentiment_score),
    positive_reviews = sum(sentiment_class == "Positive"),
    negative_reviews = sum(sentiment_class == "Negative"),
    neutral_reviews = sum(sentiment_class == "Neutral"),
    total_reviews = n(),
    perc_positive = positive_reviews / total_reviews * 100,
    perc_negative = negative_reviews / total_reviews * 100,
    perc_neutral = neutral_reviews / total_reviews * 100,
    .groups = "drop"
  ) |>
  select(
    Produkttyp,
    avg_sentiment_score,
    perc_positive,
    perc_negative,
    perc_neutral
  ) |>
  pivot_longer(
    cols = starts_with("perc_"),
    names_to = "sentiment",
    values_to = "percentage"
  ) |>
  mutate(
    sentiment = str_remove(sentiment, "perc_"),
    sentiment = recode(
      sentiment,
      positive = "Positiv",
      negative = "Negativ",
      neutral = "Neutral"
    )
  )
```

```{r}
#| fig-height: 2.050507

sentimentclass_plot <- sentiment_summary_per_class |>
  ggplot(aes(x = percentage / 100, y = Produkttyp, fill = sentiment)) +
  geom_col(position = position_stack()) +
  geom_text(
    data = sentiment_summary_per_class |>
      group_by(Produkttyp) |>
      summarise(
        label = paste0("Ø Sentiment: ", round(mean(avg_sentiment_score), 2))
      ),
    aes(y = Produkttyp, x = 97.5 / 100, label = label),
    inherit.aes = FALSE,
    size = 4,
    hjust = 1,
    col = "white"
  ) +
  # coord_flip(clip = "off") +
  scale_fill_manual(
    values = c(
      "Positiv" = "#39b185",
      "Negativ" = "#cf597e",
      "Neutral" = "#e9e29c"
    )
  ) +
  scale_x_continuous(
    # expand = expansion(mult = c(0, 0.05)), limits = c(0, 105),
    labels = scales::label_percent(accuracy = 1)
  ) +
  labs(y = NULL, fill = NULL, x = "Prozent") +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(panel.grid.major.y = element_blank())


if (interactive()) {
  3 * 0.25 + calc_panel_margin_y_in(sentimentclass_plot)
}

sentimentclass_plot
```

Um die Stimmung in den Rezensionen je Produktkategorie besser einordnen zu können, wurden die Anteile positiver, negativer und neutraler Bewertungen berechnet und in einem Vergleichsdiagramm nach Produktgruppen visualisiert.

Die Kategorie *Telefonzubehör* sticht positiv hervor: Sie weist nicht nur den höchsten durchschnittlichen Sentimentwert auf (+0.45), sondern auch den größten Anteil an positiv formulierten Rezensionen (52%).

*Kopfhörer* hingegen erreichen den niedrigsten Sentimentwert (-0.37) und haben zugleich den geringsten Anteil an positiven Kommentaren (38%). Diese Ergebnisse decken sich mit den bisherigen Beobachtungen.


```{r}
#| fig-height: 3.505128

# Sys.setlocale("LC_ALL", "de_DE.UTF-8")

review_summary <- review_summary |>
  # mutate(Datum = lubridate::dmy(Datum, locale = "de_DE.UTF-8"))
  mutate(Datum = lubridate::dmy(Datum))

sent_time_q <- review_summary |>
  filter(!is.na(Datum)) |>
  mutate(Quartal = floor_date(Datum, "quarter")) |>
  group_by(Produkttyp, Quartal) |>
  summarise(
    avg_sent = mean(sentiment_score, na.rm = TRUE),
    n_rev = n(),
    .groups = "drop"
  )

sent_time <-
  ggplot(sent_time_q, aes(Quartal, avg_sent, color = Produkttyp)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed", colour = "grey60") +
  labs(
    x = NULL,
    y = "Ø Sentiment (quartalsweise)",
    color = "Produkttyp"
  ) +
  ylim(-10, 10) +
  rcartocolor::scale_color_carto_d(type = "diverging", palette = "Temps") +
  theme(
    legend.text = ggplot2::element_text(size = 12),
    legend.position = "bottom",
    panel.grid.major = element_line()
  )

sent_time
```


Über den Zeitverlauf hinweg zeigen die quartalsweisen Durchschnittswerte des Sentiments in den frühen Jahren teils starke Schwankungen, besonders bei *Kopfhörern* und *Telefonzubehör.* Ab etwa 2018 pendeln sich die Werte aller Produktkategorien nahe der neutralen Linie ein, mit leichten positiven Ausschlägen in den letzten Quartalen. Diese Entwicklung deutet auf eine zunehmende Stabilität in der Kundenwahrnehmung hin und ermöglicht es, potenzielle Stimmungseinbrüche frühzeitig zu erkennen und gezielt gegenzusteuern.


Während diese Gesamtentwicklung ein nützliches Stimmungsbarometer darstellt, bleibt jedoch unklar, welche konkreten Produktaspekte zu positiven oder negativen Bewertungen führen. Hier setzt die **aspektbasierte Sentimentanalyse (ABSA)**. Anstatt nur das Gesamtsentiment zu messen, wird jede Rezension auf **inhaltliche Schwerpunkte** wie Preis, Funktionalität, Qualität oder Service untersucht. So lässt sich nachvollziehen, ob ein Produkt trotz positiver Gesamtbewertung z. B. wegen mangelhafter Qualität kritisiert wird oder ob ein guter Service die Stimmung hebt.


```{r}
#| fig-height: 3.505128

sentences <- reviews |>
  select(ID, Produkttyp, Inhalt) |>
  unnest_tokens(sentence, Inhalt, token = "sentences") |>
  group_by(ID) |>
  mutate(sent_idx = row_number(), sent_key = paste(ID, sent_idx, sep = "::")) |>
  ungroup()

id_map <- tibble(
  doc_id = seq_len(nrow(sentences)),
  sent_key = sentences$sent_key
)

sent_tbl <- vns::calc_tok_sentidict_tbl(
  sentences$sentence,
  .sentidict_tbl = vns.data::gerpolclu_tbl
) |>
  group_by(doc_id) |>
  summarise(sent_score = sum(tok_pol_num, na.rm = TRUE), .groups = "drop") |>
  left_join(id_map, by = "doc_id") |>
  select(sent_key, sent_score)

map_aspect <- function(x) {
  x <- stringi::stri_trans_tolower(x)
  case_when(
    str_detect(
      x,
      regex("preis|teuer|g(ü|u)nstig|billig|preis[- ]?leistung|kosten", TRUE)
    ) ~
      "Preis",
    str_detect(
      x,
      regex(
        "liefer|versand|kundendienst|service|support|r(ü|u)ckgab|antwort|hilfe",
        TRUE
      )
    ) ~
      "Service",
    str_detect(
      x,
      regex(
        "funktion|funktioniert|akku|laufzeit|kompatib|bedien|einstell|app|software",
        TRUE
      )
    ) ~
      "Funktionalität",
    str_detect(
      x,
      regex(
        "qualit(ä|a)t|verarbeitung|material|haltbar|lebensdauer|defekt|kaputt|bruch|kabel|wackelkontakt",
        TRUE
      )
    ) ~
      "Qualität",
    TRUE ~ NA_character_
  )
}

sent_aspects <- sentences |>
  mutate(Aspect = map_aspect(sentence)) |>
  filter(!is.na(Aspect)) |>
  left_join(sent_tbl, by = "sent_key") |>
  mutate(sent_score = replace_na(sent_score, 0))

min_n <- 10
aspect_summary <- sent_aspects |>
  group_by(Produkttyp, Aspect) |>
  summarise(n_mentions = n(), avg_sent = mean(sent_score), .groups = "drop") |>
  filter(n_mentions >= min_n)

asbs_plot <-
  ggplot(aspect_summary, aes(x = Aspect, y = avg_sent, fill = Produkttyp)) +
  geom_col(position = position_dodge(width = 0.7), width = 0.65) +
  geom_hline(yintercept = 0, colour = "grey60") +
  rcartocolor::scale_fill_carto_d(type = "diverging", palette = "Temps") +
  labs(x = NULL, y = "Ø Sentiment", fill = NULL) +
  theme(
    panel.grid.major.x = element_blank()
  )

asbs_plot

```


Die durchschnittlichen Sentimentwerte je Aspekt zeigen deutliche Unterschiede zwischen den Produktkategorien. Während **Preis** in allen Kategorien überwiegend positiv bewertet wird, schneidet **Qualität** insbesondere bei *Kopfhörern* negativ ab. **Funktionalität** wird insgesamt neutral bis leicht negativ wahrgenommen, wohingegen der Aspekt **Service** vor allem bei *Telefonzubehör* besonders positiv bewertet wird. Diese Auswertung verdeutlicht, welche **Stärken und Schwächen aus Kundensicht je Kategorie** vorliegen.

Die Sentimentanalysen zeigen, dass insbesondere in der Kategorie *Kopfhörer* eine hohe Unzufriedenheit besteht.
Um die Ursachen dieser negativen Bewertungen besser zu verstehen, wird im Folgenden die Analyse gezielt auf diese Produktkategorie fokussiert. Ziel ist, herauszufinden, welche konkreten Probleme Kund:innen in Verbindung mit Kopfhörern am häufigsten nennen.


#### Analyse der Bigramme 

Da die Sentimentanalyse bei Kopfhörern stark negativ ausfiel, lohnt es sich einen genaueren Blick auf wiederkehrende **Wortpaare** (Bigramme) zu werfen. Bigramme zeigen, welche Begriffe in den Rezensionen besonders häufig direkt aufeinander folgen und damit inhaltlich zusammengehören. So lassen sich typische Formulierungen und wiederkehrende Sprachmuster identifizieren, die bei der Analyse einzelner Wörter verborgen bleiben.

Eine Untersuchung der am häufigsten vorkommenden Bigramme in den Rezensionen für *Kopfhörer* offenbart ein zentrales Problem:

```{r}
#| fig-height: 1.926543

bigrams_worst <- reviews |>
  filter(Produkttyp == "Kopfhörer") |>
  unnest_tokens(bigram, Inhalt, token = "ngrams", n = 2) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(
    !word1 %in% custom_stopwords$Wort,
    !word2 %in% custom_stopwords$Wort,
    !str_detect(word1, "^\\d+$"),
    !str_detect(word2, "^\\d+$")
  ) |>
  unite(bigram, word1, word2, sep = "_")

bigrams_worst_plot <-
  bigrams_worst |>
  count(bigram, sort = TRUE) |>
  slice_max(n, n = 5) |>
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col(fill = "#46aea0") +
  coord_flip() +
  scale_x_discrete(
    labels = \(.labs) {
      stringi::stri_replace_all_fixed(.labs, "_", " ")
    }
  ) +
  labs(x = NULL, y = "Anzahl") +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  5 * 0.25 + calc_panel_margin_y_in(bigrams_worst_plot)
}

bigrams_worst_plot
```


Wortpaare wie „kaputt gegangen“, „monaten kaputt“, oder „kurzer zeit“ zeigen, dass viele Bewertungen auf schnelle Defekte und kurze Lebensdauer hinweisen. Kund:innen berichten von frühzeitigen Ausfällen, oft bereits nach wenigen Wochen oder Monaten.

Welche konkreten Themen die Konsumenten bezüglich der Produktkategorie *Kopfhörer* beschäftigt, wird im nächsten Schritt mithilfe einer Themenmodellierung betrachtet.




#### Themenmodellierung

Um die zentralen Kritikpunkte in den Rezensionen zur Produktkategorie *Kopfhörer* präziser herauszuarbeiten, berechnen wir im nächsten Schritt ein **Structural Topic Modelling (STM)**. Diese Methode bietet die Möglichkeit andere Faktoren, die die Themen beeinflussen könnten, zu berücksichtigen, wie die Bewertungen der Kund:innen und das Datum, an dem die Rezension verfasst wurde. Für unser Korpus ergeben sich fünf Schwerpunkte: Langlebigkeit, Verarbeitung, Passform, Sound und Preis-Leistung.

Die folgende Grafik zeigt für jedes Thema die repräsentativsten Begriffe. So wird deutlich, warum wir die Themen so benannt haben (z.B. „monaten“, „wochen“ oder "lebensdauer" im Thema *Langlebigkeit*).



```{r}
#| output: false

custom_stopwords_ext <- custom_stopwords |>
  # fmt: skip
  tibble::add_case(Wort = c(
    "leider", "immer", "besser", "produkt", "amazon", "bestellt", "kunden", 
    "gerät", "geräte", "artikel", "funktioniert", "super", "jbl", "sony", 
    "gehen", "kaputt", "rechte", "linke", "köpfhörer", "absolut", "gutes", 
    "gut", "schlechtes", "schlecht", "erwarten", "hören", "tag", "zweite", 
    "richtig", "lange", "musik", "hörer", "gekauft", "kaufen", "produkt", 
    "benutzung", "sterne", "größe", "jahren", "gegangen", "benutze", 
    "kopfhörern", "stern", "preis", "sound", "klang"
  )) |>
  distinct() |>
  filter(!is.na(Wort), Wort != "")


review_tokens_clean <- review_tokens |>
  filter(!str_detect(Wort, "^\\d+$|^[sa]\\d+$|^[0-9]+[a-z]*$")) |>
  anti_join(custom_stopwords_ext, by = "Wort") |>
  filter(str_count(Wort) >= 3)

df_tbl <- review_tokens_clean |>
  distinct(ID, Wort) |>
  count(Wort, name = "doc_n")

n_docs <- n_distinct(review_tokens_clean$ID)

review_tokens_clean <- review_tokens_clean |>
  inner_join(df_tbl, by = "Wort") |>
  filter(doc_n >= 10, doc_n <= 0.70 * n_docs) |>
  select(-doc_n)

tokens_for_stm <- review_tokens_clean |>
  mutate(
    Wort_raw = Wort,
    # Wort = SnowballC::wordStem(Wort, language = "german")
    Wort = quanteda::char_wordstem(Wort, language = "de")
  )

keep_ids <- tokens_for_stm |>
  count(ID) |>
  filter(n >= 10) |>
  pull(ID)

tokens_for_stm <- tokens_for_stm |>
  filter(ID %in% keep_ids)


library(stm)

docs_worst <- tokens_for_stm |>
  filter(Produkttyp == "Kopfhörer") |>
  group_by(ID) |>
  summarise(text = paste(Wort, collapse = " "), .groups = "drop")

meta_worst <- reviews |>
  filter(Produkttyp == "Kopfhörer", ID %in% docs_worst$ID) |>
  mutate(Bewertung = as.factor(Bewertung)) |>
  arrange(match(ID, docs_worst$ID))

processed <- textProcessor(
  documents = docs_worst$text,
  metadata = meta_worst,
  language = "de",
  stem = FALSE,
  wordLengths = c(3, Inf)
)

out <- prepDocuments(
  documents = processed$documents,
  vocab = processed$vocab,
  meta = processed$meta,
  verbose = FALSE
)

stm_model <- stm(
  documents = out$documents,
  vocab = out$vocab,
  K = 5,
  prevalence = ~ Bewertung +
    Produkt +
    lubridate::dmy(Datum, locale = "de_DE.UTF-8"),
  data = out$meta,
  init.type = "Spectral",
  verbose = FALSE,
  seed = 123
)

```



```{r}
#| fig-height: 6.602073

stem_label_map <- tokens_for_stm |>
  count(Wort, Wort_raw, sort = TRUE) |>
  group_by(Wort) |>
  slice_max(n, n = 1, with_ties = FALSE) |>
  ungroup() |>
  select(stem = Wort, show = Wort_raw)

top_terms <- tidy(stm_model, matrix = "beta") |>
  group_by(topic) |>
  slice_max(beta, n = 10, with_ties = FALSE) |>
  ungroup() |>
  left_join(stem_label_map, by = c("term" = "stem")) |>
  mutate(show = coalesce(show, term))

topic_labels <- tibble(
  topic = sort(unique(top_terms$topic)),
  label = c(
    "Langlebigkeit",
    "Verarbeitung",
    "Passform",
    "Sound",
    "Preis-Leistung"
  )[seq_along(unique(top_terms$topic))],
  col = c(
    "#cf597e",
    "#e9e29c",
    "#009392",
    "#9ccb86",
    "#eeb479"
  )[seq_along(unique(top_terms$topic))]
)
pal <- setNames(topic_labels$col, topic_labels$label)


topic_plot <-
  top_terms |>
  left_join(topic_labels, by = "topic") |>
  mutate(
    topic_lab = factor(label, levels = topic_labels$label),
    show = reorder_within(show, beta, topic_lab)
  ) |>
  ggplot(aes(show, beta, fill = topic_lab)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic_lab, scales = "free") +
  scale_x_reordered() +
  coord_flip() +
  labs(x = NULL, y = "Gewichtung") +
  scale_fill_manual(values = pal) +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  # spacing between grid rows is ~15mm
  grid::convertUnit(unit(15, "mm"), "in", valueOnly = TRUE)
  20 * 0.25 + calc_panel_margin_y_in(topic_plot) + 0.59
}

topic_plot
```

Direkt anschließend betrachten wir, wie häufig diese Themen im Gesamtkorpus auftreten. Die Balkenhöhen geben die durchschnittliche Dokument‑Wahrscheinlichkeit je Thema an, was dem durchschnittlichen Anteil entspricht, den ein Thema an einer Rezension hat. Dadurch sehen wir nicht nur Beispiele, sondern die gewichtete Verteilung der Themen über alle Rezensionen hinweg.


```{r}
#| fig-height: 1.926543

# distribution of words across documents
td_beta <- tidy(stm_model)

td_gamma <- tidy(
  stm_model,
  matrix = "gamma",
  document_names = rownames(reviews)
)

gamma_terms <- td_gamma |>
  group_by(topic) |>
  summarise(gamma = mean(gamma)) |>
  arrange(desc(gamma)) |>
  left_join(topic_labels, by = "topic") |>
  mutate(topic = reorder(topic, gamma)) |>
  select(-topic)

topic_doc_distr <-
  gamma_terms |>
  top_n(20, gamma) |>
  mutate(label = reorder(label, gamma)) |>
  ggplot(aes(label, gamma, label = label, fill = label)) +
  geom_col(show.legend = FALSE) +
  # geom_text(hjust = 0, nudge_y = 0.005, size = 4, family = "Open Sans") +
  coord_flip() +
  labs(x = "Repräsentative\n Begriffe", y = "Gewichtung") +
  rcartocolor::scale_fill_carto_d(type = "diverging", palette = "Temps") +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  5 * 0.25 + calc_panel_margin_y_in(topic_doc_distr)
}


topic_doc_distr

```


Die Themen treten insgesamt relativ ausgeglichen auf, mit leicht höheren Anteilen für *Langlebigkeit* und *Preis-Leistung*, gefolgt von *Sound*, *Verarbeitung* und *Passform.*


```{r}
topic_assignments <- as_tibble(stm_model$theta) |>
  mutate(ID = out$meta$ID) |>
  pivot_longer(
    cols = starts_with("V"),
    names_to = "topic",
    names_prefix = "V",
    names_transform = list(topic = as.integer),
    values_to = "gamma"
  ) |>
  group_by(ID) |>
  slice_max(order_by = gamma, n = 1) |>
  ungroup()

topic_sentiment <- topic_assignments |>
  mutate(ID = as.character(ID)) |>
  left_join(
    review_summary |> select(ID, sentiment_score),
    by = "ID"
  )
```



```{r}
#| fig-height: 1.926543

topic_summary <- topic_sentiment |>
  group_by(topic) |>
  summarise(
    avg_sentiment = mean(sentiment_score, na.rm = TRUE),
    n_reviews = n()
  ) |>
  arrange(avg_sentiment) |>
  left_join(
    topic_labels,
    by = "topic"
  ) |>
  select(label, avg_sentiment, n_reviews)


topic_summary_plot <- topic_summary |>
  mutate(label = forcats::fct_reorder(label, avg_sentiment)) |>
  ggplot(aes(x = label, y = avg_sentiment, fill = label)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous() +
  labs(
    x = NULL,
    y = "Ø Sentimentwert",
  ) +
  coord_flip() +
  scale_fill_manual(values = pal) +
  theme(panel.grid.major.y = element_blank())

if (interactive()) {
  5 * 0.25 + calc_panel_margin_y_in(topic_summary_plot)
}

topic_summary_plot
```


Nachdem wir die Häufigkeit der Themen im Gesamtkorpus betrachtet haben, wenden wir uns nun der Frage zu, wie positiv oder negativ diese jeweils bewertet werden. Die Analyse der Sentimentwerte pro Thema zeigt: Am stärksten negativ wird die *Verarbeitung* bewertet. Auch beim *Sound* äußern Kunden deutliche Kritik, vermutlich aufgrund auftretender Probleme bei hohen Tönen, wie aus der Worthäufigkeitsanalyse der Themen hervorgeht. Die Themen *Preis-Leistung*, *Passform* und *Langlebigkeit* schneiden im Vergleich etwas besser ab, weisen jedoch ebenfalls einen negativen Grundton auf. 


```{r}
#| fig-height: 2.317425

doc_gamma <- as_tibble(stm_model$theta) |>
  mutate(
    ID = as.character(out$meta$ID),
    Datum = out$meta$Datum
  ) |>
  pivot_longer(
    starts_with("V"),
    names_to = "topic",
    names_prefix = "V",
    names_transform = list(topic = as.integer),
    values_to = "gamma"
  ) |>
  left_join(topic_labels, by = "topic") |>
  filter(!is.na(Datum)) |>
  mutate(
    Datum = lubridate::dmy(Datum, locale = "de_DE.UTF-8"),
    Quartal = lubridate::floor_date(Datum, "quarter")
  )

topic_share_q <- doc_gamma |>
  filter(label %in% topic_labels$label) |>
  group_by(Quartal, label) |>
  summarise(share = mean(gamma, na.rm = TRUE), .groups = "drop") |>
  group_by(Quartal) |>
  mutate(share = share / sum(share)) |>
  ungroup()

stacked_topics_plot <-
  ggplot(
    topic_share_q |>
      filter(Quartal >= as.Date("2017-01-01")),
    aes(x = Quartal, y = share, fill = label)
  ) +
  geom_area(position = "fill", alpha = 0.9, color = NA) +
  scale_fill_manual(values = pal, name = NULL) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(x = NULL, y = "Anteil der\nThemen") +
  theme(panel.grid.minor = element_blank(), legend.position = "bottom")

if (interactive()) {
  5 * 0.25 + calc_panel_margin_y_in(stacked_topics_plot)
}


stacked_topics_plot

```

Die zeitliche Entwicklung der Themenanteile zeigt deutliche Verschiebungen in den Rezensionen: 2017 dominierten noch *Passform* und *Verarbeitung*, die in den ersten Monaten besonders häufig genannt wurden. Im Zeitverlauf rückten dagegen *Sound*, *Preis‑Leistung* und *Langlebigkeit* in den Vordergrund und lösten die zuvor dominierenden Themen ab. Das deutet darauf hin, dass sich die Kundenerwartungen von der anfänglichen Produktanpassung hin zu langfristiger Qualität zu einem fairen Preis verlagert haben. Positiv anzumerken ist, dass damit das Thema mit der negativsten Stimmung deutlich zurückgegangen ist.



### Fazit

In dieser Fallstudie haben wir gezeigt, welches Potenzial in der **systematischen Auswertung von Kundenrezensionen** steckt. Der freie Text in Rezensionen liefert wertvolle Informationen, ohne dass zusätzliche Befragungen oder aufwändige Erhebungen notwendig sind, wodurch **Ressourcen gespart** und anders eingesetzt werden können. Mithilfe geeigneter Analysemethoden lassen sich daraus konkrete Hinweise auf Produktqualität, Nutzererwartungen und mögliche Verbesserungspotenziale ableiten. Darüber hinaus kann die Analyse als **Echtzeit-Stimmungsbarometer** dienen. Unternehmen können frühzeitig erkennen, wenn sich negative Trends abzeichnen, und zeitnah reagieren, etwa durch Qualitätsverbesserungen, gezielte Kundenkommunikation oder Anpassung des Serviceangebots. So lassen sich Schwachstellen schneller beheben und die Produkte noch konsequenter an den Bedürfnissen der Kund:innen ausrichten.

```{r}
review_tokens_clean |>
  count(Wort, sort = TRUE) |>
  readr::write_rds(here::here("content", "data", "wordcloud_data.rds"))
```

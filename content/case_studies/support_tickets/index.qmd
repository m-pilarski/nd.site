---
title: "Analyse von Support-Tickets"
subtitle: "Wie maschinelles Lernen hilft, dringende Kundenanliegen fr√ºhzeitig zu erkennen."
figtitle: "üì©"
date: "2024-11-25T14:25:49+01:00"
draft: false
toc_show: true
execute:
  echo: false
  message: false
---


```{r}
#| cache: false

# Setup
set.seed(123)

library(tidyverse)
library(tidytext)
library(textdata)
library(lubridate)
library(topicmodels)
# library(tm)
# library(wordcloud)
# library(stopwords)
library(ggplot2)
# library(textrecipes)
library(gt)

data_dir <- here::here("content", "case_studies", "support_tickets", "data")

calc_panel_margin_y_in <- function(.plot_obj) {
  .plot_obj |>
    plottr::calc_element_margin_data() |>
    dplyr::filter(
      stringi::stri_detect_regex(name, "^panel(-\\d+)*$")
    ) |>
    dplyr::summarize(
      margin_top = min(plottr:::unit_to_mm(margin_top)),
      margin_bottom = min(plottr:::unit_to_mm(margin_bottom))
    ) |>
    with(unit(margin_bottom + margin_top, "mm")) |>
    grid::convertUnit("in", valueOnly = TRUE)
}

ggplot2::theme_set(`+`(
  ggplot2::theme_minimal(base_size = 14, base_family = "Open Sans"),
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(size = 12),
    axis.text.y = ggplot2::element_text(size = 12),
    axis.title.x = ggplot2::element_text(size = 14),
    axis.title.y = ggplot2::element_text(size = 14),
    title = ggplot2::element_text(size = 14),
    strip.text = ggplot2::element_text(size = 14),
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.background = ggplot2::element_rect(fill = NA, colour = NA),
    plot.background = ggplot2::element_rect(fill = NA, colour = NA),
    legend.position = "bottom"
  )
))
```

  
T√§glich erreichen Unternehmen zahlreiche Anfragen, Beschwerden oder sonstige Mitteilungen. Um diese effizient zu verwalten, kommen Support-Systeme zum Einsatz, die Kundenanliegen strukturieren und kategorisieren. Doch selbst mit diesen Systemen vergeht oftmals wertvolle Zeit, bis dringende Kundenanliegen an die richtige Stelle gelangen, mit l√§ngeren Ausfallzeiten und sinkender Kundenzufriedenheit als m√∂gliche Folgen.

In diesem Fallbeispiel zeigen wir, wie sich Methoden der Textanalyse und des maschinellen Lernens nutzen lassen, um Support-Tickets automatisiert nach ihrer Dringlichkeit zu klassifizieren. Ziel ist es, besonders wichtige Anfragen fr√ºhzeitig zu erkennen und die Kundenzufriedenheit gezielt zu steigern.

Dabei konzentrieren wir uns bewusst vor allem auf textbasierte Variablen, um zu demonstrieren, dass bereits auf dieser Basis leistungsf√§hige Klassifikationsmodelle entwickelt werden k√∂nnen.


### Laden des Datensatzes 

```{r}
#| echo: false
#| message: false

support <-
  read_rds(
    fs::path(data_dir, "german_customer_support_tickets.rds")
  ) |>
  mutate(
    row_id = row_number() |>
      as.character(),
    .before = subject
  ) |>
  mutate(
    urgency = if_else(type %in% c("Incident", "Problem"), "hoch", "gering")
  ) |>
  select(
    -paste0("tag_", 1:8),
    -answer,
    -type,
    -priority,
    -version,
    -detected_language,
    -language_mismatch
  ) |>
  rename(
    ID = row_id,
    Betreff = subject,
    Nachricht = message,
    Bereich = queue,
    Sprache = language,
    Dringlichkeit = urgency
  ) |>
  mutate(
    Bereich = case_when(
      Bereich == "Billing and Payments" ~ "Abrechnung und Zahlungen",
      Bereich == "Customer Service" ~ "Kundenservice",
      Bereich == "General Inquiry" ~ "Allgemeine Anfrage",
      Bereich == "Human Resources" ~ "Personalabteilung",
      Bereich == "IT Support" ~ "IT-Support",
      Bereich == "Product Support" ~ "Produktsupport",
      Bereich == "Returns and Exchanges" ~ "R√ºckgaben und Umtausch",
      Bereich == "Sales and Pre-Sales" ~ "Vertrieb und Vorverkauf",
      Bereich == "Service Outages and Maintenance" ~ "Wartung und St√∂rungen",
      Bereich == "Technical Support" ~ "Technischer Support",
      TRUE ~ Bereich
    )
  )
```

```{r}
library(htmltools)

support |>
  slice_sample(n = 10) |>
  mutate(
    Betreff,
    Nachricht,
    Bereich,
    Sprache,
    Dringlichkeit,
    .keep = "none"
  ) |>
  as.list() |>
  list_transpose() |>
  map(\(.row_list) {
    tags$div(
      class = "card",
      style = "width: 100%;",
      tags$ul(
        class = "list-group list-group-flush",
        !!!unname(imap(.row_list, \(.value, .key) {
          tags$li(
            class = "list-group-item",
            tags$div(
              style = stringi::stri_c(
                "overflow: hidden; width: 100%; display: -webkit-box; ",
                "-webkit-line-clamp: 8; -webkit-box-orient: vertical;"
              ),
              tags$code(stringi::stri_c(.key, ":")),
              .value
            )
          )
        }))
      )
    )
  }) |>
  nd.util::nd_carousel(.title = "Beispielbeobachtungen aus dem Rohdatensatz")
```


### Vorverarbeitung

Bevor der Text f√ºr weitere Analysen genutzt werden kann, muss er, wie in den {{{< crossref path="/basics#textdaten-f√ºr-analysen-vorbereiten" label="Grundlagen" >}}} beschrieben, in ein geeignetes Format √ºberf√ºhrt werden.

Dazu entfernen wir unter anderem sogenannte **Stoppw√∂rter**, also sehr h√§ufige W√∂rter ohne inhaltliche Aussagekraft. Zus√§tzlich bereinigen wir die Texte um wiederkehrende Formulierungen wie ‚ÄûSehr geehrtes Support-Team‚Äú oder ‚ÄûSehr geehrter Kundenservice‚Äú, da auch diese keinen Mehrwert f√ºr die inhaltliche Analyse bieten.

Anschlie√üend wird der Text **tokenisiert**, also in einzelne W√∂rter zerlegt. Dies ist ein grundlegender Schritt, um unstrukturierte Sprache in eine **strukturierte Form** zu bringen, die sich systematisch analysieren l√§sst, etwa durch das Z√§hlen oder Vergleichen sprachlicher Einheiten, wie W√∂rtern.


```{r}
#| echo: false
#| message: false

custom_stopwords <-
  quanteda::stopwords(language = "de", source = "nltk") |>
  # fmt: skip
  c(
    "sehr", "geehrtes", "support", "kundensupport", "team", "kundendienstteam",
    "kundenservice", "nachricht", "kundendienst", "hoffe", "erreicht" 
  ) |>
  unique() |>
  tibble::as_tibble_col("word")

support_tokens_clean <- support |>
  mutate(
    Nachricht = str_replace_all(Nachricht, "\\\\n", " "),
    Nachricht = str_to_lower(Nachricht)
  ) |>
  unnest_tokens(word, Nachricht) |>
  filter(
    !str_detect(word, "^\\d+$|^[sa]\\d+$|^[0-9]+[a-z]*$"),
    !word %in% custom_stopwords$word
  )
```

```{r}
support_tokens_clean |>
  head(5) |>
  gt::gt() |>
  gt::tab_caption("Beispiel der ersten Beobachtung nach dem Preprocessing") |>
  gt::tab_options(
    table.width = gt::pct(100),
    data_row.padding = gt::px(4),
    ihtml.use_pagination = FALSE,
    ihtml.use_text_wrapping = TRUE
  ) |>
  nd.util::nd_gt_tab_options() |>
  nd.util::nd_gt_to_html()
```


```{r}
format_token <- function(.tok) {
  .tok |>
    map_chr(\(..str) {
      stringi::stri_c("\"", ..str, "\"")
    }) |>
    stringi::stri_c(collapse = ", ") |>
    (\(..str) {
      stringi::stri_c("[", ..str, "]")
    })()
}

msg_full <- support |>
  purrr::pluck("Nachricht", 1) |>
  stringi::stri_replace_all_fixed("\\n", "\n")

msg_token <- msg_full |>
  stringi::stri_trans_tolower() |>
  stringi::stri_split_boundaries(type = "word", skip_word_none = TRUE) |>
  purrr::pluck(1)

msg_prep <- msg_token |>
  stringi::stri_subset_regex(
    "^\\d+$|^[sa]\\d+$|^[0-9]+[a-z]*$",
    negate = TRUE
  ) |>
  setdiff(pull(custom_stopwords, word))

tags$div(
  class = "d-flex flex-column justify-content-center",
  tags$div(
    class = "card nd-card",
    style = "background-color: #e9ebe5;",
    msg_full
  ),
  tags$i(class = "fa-solid fa-arrow-down"),
  tags$div(
    class = "card nd-card",
    style = "background-color: #e9ebe5;",
    format_token(msg_token)
  ),
  tags$i(class = "fa-solid fa-arrow-down"),
  tags$div(
    class = "card nd-card",
    style = "background-color: #e9ebe5;",
    format_token(msg_prep)
  )
)

```



### Analyse

#### Worth√§ufigkeiten

Bevor wir mit der Modellierung beginnen, schauen wir uns den Datensatz etwas genauer an, um ein besseres Verst√§ndnis f√ºr die enthaltenen Texte zu gewinnen. Insbesondere bei textbasierten Daten bietet es sich an, zun√§chst **Worth√§ufigkeiten** zu betrachten, um zentrale Begriffe und m√∂gliche Muster zu erkennen.

Die zehn h√§ufigsten Begriffe im Datensatz deuten darauf hin, dass der Kundenservice vor allem bei technischen Problemen oder Fragen zur Software kontaktiert wird. 

```{r}
# word freq
top_words <- support_tokens_clean |>
  count(word, sort = TRUE)

freq_plot <- top_words |>
  slice_head(n = 10) |>
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(show.legend = FALSE, fill = "#837591") +
  coord_flip() +
  labs(x = "Wort", y = "Anzahl")
```

```{r}
#| fig-height: 3.173071

freq_plot
```


Allerdings wird hiermit noch nicht deutlich, welche Begriffe dringendere Nachrichten darstellen. Dazu betrachten wir in der n√§chsten Abbildung die h√§ufigsten Begriffe nach Dringlichkeit. 

```{r}

freq_per_class_plot <-
  support_tokens_clean |>
  count(Dringlichkeit, word, sort = TRUE) |>
  group_by(Dringlichkeit) |>
  slice_max(n, n = 10) |>
  ungroup() |>
  ggplot(aes(
    x = reorder_within(word, n, Dringlichkeit),
    y = n,
    fill = Dringlichkeit
  )) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Dringlichkeit, scales = "free_y") +
  scale_x_reordered() +
  coord_flip() +
  scale_fill_manual(
    values = c(
      "gering" = "#39b185",
      "hoch" = "#cf597e"
    )
  ) +
  labs(
    x = NULL,
    y = "H√§ufigkeit"
  )
```

```{r}
#| fig-height: 3.173071

freq_per_class_plot
```


Es lassen sich klare inhaltliche Unterschiede zwischen den Klassen erkennen:

{{{< fa-ul >}}}
  {{{< fa-solid-li icon="comment-dots" >}}} In weniger dringlichen Nachrichten (links) stehen eher allgemeine oder informative Begriffe im Vordergrund, wie z.B. ‚Äûinformationen‚Äú, ‚Äûfreue‚Äú, ‚Äûintegration‚Äú oder ‚Äûunterst√ºtzung‚Äú. Diese Anfragen deuten auf Interesse, Verbesserungsvorschl√§ge oder R√ºckfragen hin.{{{< /fa-solid-li >}}}

  {{{< fa-solid-li icon="triangle-exclamation" >}}} In hoch dringlichen Nachrichten (rechts) dominieren dagegen Begriffe wie ‚Äûproblem‚Äú, ‚Äûsoftware‚Äú, ‚Äûbeheben‚Äú, ‚Äûl√∂sung‚Äú oder ‚Äûursache‚Äú. Diese Begriffe weisen auf technische Schwierigkeiten oder akute St√∂rungen hin, die eine schnelle Reaktion erfordern.{{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}


#### Charakteristische Begriffe pro Klasse (TF-IDF)

Neben der Betrachtung der h√§ufigsten Begriffe ist es oft noch aufschlussreicher, charakteristische W√∂rter pro Klasse zu identifizieren. Die {{{< crossref path="/basics#tf-idf" label="TF-IDF-Methode" >}}} hebt dabei Begriffe hervor, die besonders typisch f√ºr eine Klasse sind, aber in anderen weniger h√§ufig vorkommen. So lassen sich sprachliche Muster erkennen, die beim automatisierten Erkennen der Dringlichkeit besonders hilfreich sind. Die folgende Grafik zeigt die jeweils 10 pr√§gnantesten Begriffe pro Klasse.


```{r}
#| fig-height: 2.498452

tfidf_plot <-
  support_tokens_clean |>
  count(Dringlichkeit, word) |>
  bind_tf_idf(word, Dringlichkeit, n) |>
  group_by(Dringlichkeit) |>
  slice_max(tf_idf, n = 10) |>
  ungroup() |>
  ggplot(aes(
    x = reorder_within(word, tf_idf, Dringlichkeit),
    y = tf_idf,
    fill = Dringlichkeit
  )) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Dringlichkeit, scales = "free_y") +
  scale_x_reordered() +
  scale_y_continuous(
  breaks = scales::breaks_pretty(n = 3)
  ) +
  coord_flip() +
  scale_fill_manual(
    values = c(
      "gering" = "#39b185",
      "hoch" = "#cf597e"
    )
  ) +
  labs(
    y = "TF-IDF Wert",
    x = NULL
  )
```

```{r}
tfidf_plot
```


#### Textbasierte Merkmalsextraktion

Um die Dringlichkeit von Nachrichten automatisch einsch√§tzen zu k√∂nnen, m√ºssen aus dem Text sinnvolle **Merkmale** gewonnen werden. Dabei helfen sprachliche Hinweise wie **Ausrufezeichen**, **Fragen** oder die **durchschnittliche Wortl√§nge**. Solche Merkmale lassen sich mit sogenannten **Regular Expressions** erkennen. Das sind spezielle Suchmuster, mit denen bestimmte Zeichenfolgen im Text gezielt gefunden und gez√§hlt werden k√∂nnen, etwa Ausrufezeichen oder Fragew√∂rter.

Diese Merkmalsextraktion bildet die **Grundlage f√ºr das Klassifikationsmodell**: Je pr√§ziser die relevanten Muster erkannt werden, desto besser kann das System dringende Anliegen priorisieren und schnell an die richtige Stelle leiten.


```{r}
support_clean <- support |>
  mutate(
    Zeichenanzahl = str_length(Nachricht),
    `Anzahl Ausrufezeichen` = str_count(Nachricht, "!"),
    Wortanzahl = str_count(Nachricht, "\\w+"),
    Frage = str_detect(Nachricht, "\\?") |> factor(),
    Wortl√§nge = str_extract_all(Nachricht, "\\w+") |>
      map_dbl(~ mean(nchar(.x), na.rm = TRUE)),
    `Betreff vorhanden` = (!is.na(Betreff) &
      str_length(str_trim(Betreff)) > 0) |>
      factor(),
    Nachricht = str_replace_all(Nachricht, "\\\\n", " "),
    Nachricht = str_to_lower(Nachricht),
    Nachricht = str_remove_all(
      Nachricht,
      "\\b\\d+\\b|\\b[sa]\\d+\\b|\\b[0-9]+[a-z]*\\b"
    ),
    Nachricht = str_remove_all(
      Nachricht,
      paste0("\\b(", paste(custom_stopwords$word, collapse = "|"), ")\\b")
    ),
    Nachricht = str_squish(Nachricht),
    Nachricht = str_replace_all(Nachricht, "[[:punct:]]", " "),
    Nachricht = str_replace_all(Nachricht, "\\s+", " "),
    Nachricht = str_trim(Nachricht)
  ) |>
  mutate(Zeichenanzahl = str_length(Nachricht)) |>
  filter(Zeichenanzahl >= 10)


comp_table <- support_clean |>
  group_by(Dringlichkeit) |>
  summarise(
    `√ò Zeichenanzahl` = mean(Zeichenanzahl, na.rm = TRUE),
    `√ò Wortanzahl` = mean(Wortanzahl, na.rm = TRUE),
    `√ò Wortl√§nge` = mean(Wortl√§nge, na.rm = TRUE),
    `√ò Ausrufezeichen` = mean(`Anzahl Ausrufezeichen`, na.rm = TRUE),
    `Fragenanteil` = mean(as.numeric(Frage) == 1, na.rm = TRUE),
    `Betreff vorhanden` = mean(
      as.numeric(`Betreff vorhanden`) == 1,
      na.rm = TRUE
    ),
    .groups = "drop"
  )

library(gt)

comp_table |>
  pivot_longer(-Dringlichkeit) |>
  pivot_wider(names_from = Dringlichkeit, values_from = value) |>
  gt::gt(rowname_col = "name") |>
  gt::tab_caption("Vergleich sprachlicher Merkmale nach Dringlichkeit") |>
  gt::fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) |>
  gt::fmt_percent(
    rows = c("Fragenanteil", "Betreff vorhanden")
  ) |>
  gt::cols_align_decimal(dec_mark = ".") |>
  gt::tab_spanner(
    label = "Dringlichkeit",
    columns = c(gering, hoch)
  ) |>
  gt::tab_options(table.width = gt::pct(100)) |>
  nd.util::nd_gt_tab_options() |>
  nd.util::nd_gt_to_html()
```


Ein Vergleich sprachlicher Merkmale zeigt deutliche Unterschiede zwischen dringenden und weniger dringenden Nachrichten. Besonders auff√§llig ist der Fragenanteil: W√§hrend nur etwa 39% der weniger dringenden Nachrichten eine Frage enthalten, liegt dieser Anteil bei dringenden Nachrichten bei √ºber 92%. Auch die durchschnittliche Wortl√§nge ist bei dringenden Anliegen leicht erh√∂ht.

Andere Merkmale wie Zeichen- und Wortanzahl oder der Einsatz von Ausrufezeichen unterscheiden sich dagegen kaum, und der Anteil an Nachrichten mit Betreff ist nahezu identisch. Diese Erkenntnisse sind f√ºr das Klassifikationsmodell entscheidend: Ein hoher Fragenanteil in Kombination mit leicht komplexerer Sprache, erkennbar an der h√∂heren Wortl√§nge, kann als starker Indikator f√ºr Dringlichkeit genutzt werden.


#### Sentimentanalyse 

Ein weiteres Merkmal, das f√ºr die Modellierung interessant sein k√∂nnte, ist die **sprachliche Stimmung (Sentiment):** Ist der Ton der Nachricht eher positiv oder negativ? Dazu f√ºhren wir eine einfache **lexikonbasierte Sentimentanalyse** durch. Dabei wird jeder Nachricht ein Wert zugewiesen, der die Summe der positiven und negativen Begriffe widerspiegelt. 


```{r}
## Sentiment Analysis

sentiment_tokens <- vns::calc_tok_sentidict_tbl(
  support_clean$Nachricht,
  .sentidict_tbl = vns.data::sentiws_tbl
)

support_summary <- support_clean |>
  left_join(
    sentiment_tokens |>
      group_by(doc_id = as.character(doc_id)) |>
      summarise(
        Sentimentwert = sum(tok_pol_num, na.rm = TRUE),
        .groups = "drop"
      ),
    by = c("ID" = "doc_id")
  ) |>
  mutate(
    Sentimentwert = replace_na(Sentimentwert, 0),
    sentiment_class = case_when(
      Sentimentwert > 0 ~ "positiv",
      Sentimentwert < 0 ~ "negativ",
      TRUE ~ "neutral"
    )
  )


sentiment_summary <- support_summary |>
  summarise(
    avg_sentiment_score = mean(Sentimentwert),
    median_sentiment_score = median(Sentimentwert),
    positive_reviews = sum(sentiment_class == "positiv"),
    negative_reviews = sum(sentiment_class == "negativ"),
    neutral_reviews = sum(sentiment_class == "neutral"),
    total_reviews = n()
  ) |>
  mutate(
    perc_positive = positive_reviews / total_reviews * 100,
    perc_negative = negative_reviews / total_reviews * 100,
    perc_neutral = neutral_reviews / total_reviews * 100
  )


sentiment_summary_long <- sentiment_summary |>
  select(perc_positive, perc_negative, perc_neutral) |>
  pivot_longer(
    cols = everything(),
    names_to = "Sentiment",
    values_to = "Anteil"
  ) |>
  mutate(
    Sentiment = recode(
      Sentiment,
      perc_positive = "Positiv",
      perc_negative = "Negativ",
      perc_neutral = "Neutral"
    )
  )
```



```{r}
#| fig-height: 2.050507

overall_sentiment_plot <-
  ggplot(sentiment_summary_long, aes(x = "", y = Anteil / 100, fill = Sentiment)) +
  geom_bar(stat = "identity", width = 0.4) +
  coord_flip() +
  guides(fill = guide_legend(reverse = TRUE)) +
  scale_fill_manual(
    values = c(
      "Positiv" = "#39b185",
      "Neutral" = "#e9e29c",
      "Negativ" = "#cf597e"
    )
  ) +
  scale_y_continuous(
    labels = scales::label_percent(accuracy = 1)
  ) +
  labs(x = NULL, fill = NULL, y = "Prozent") +
  guides(fill = guide_legend(reverse = TRUE)) |>
    theme(
      legend.text = ggplot2::element_text(size = 12),
      legend.position = "bottom"
    )


overall_sentiment_plot
```


Mit einem Anteil von 55.4% sind die Nachrichten √ºberwiegend sprachlich negativ geladen. Es zeigt sich auch, dass die Nachrichten eher positiv oder negativ sind, denn nur rund 3% der Nachrichten sind sprachlich neutral. Das deutet darauf hin, dass Support-Nachrichten oft emotional aufgeladen sind.

Ein Blick auf den durchschnittlichen Sentimentwert f√ºr dringende und weniger dringende Nachrichten zeigt bedeutungsvolle Unterschiede: 

```{r}
#| fig-height: 3

#Sentiment per urgency label
avg_sentiment_per_class <- support_summary |>
  group_by(Dringlichkeit) |>
  summarize(avg_sentiment = mean(Sentimentwert, na.rm = TRUE)) |>
  arrange(desc(avg_sentiment))


sentiment_per_urgency_plot <-
  support_summary |>
  ggplot(
    aes(x = Dringlichkeit, y = Sentimentwert, fill = fct_rev(Dringlichkeit))
  ) +
  geom_violin(trim = FALSE, color = NA) +
  geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
  labs(
    x = "Dringlichkeit",
    y = "Sentimentwert",
    fill = "Dringlichkeit"
  ) +
  scale_fill_manual(
    values = c(
      "gering" = "#39b185",
      "hoch" = "#cf597e"
    )
  ) +
  coord_flip() +
  theme(
    panel.grid.major = element_line(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "bottom"
  )


if (interactive()) {
  7 * 0.25 + calc_panel_margin_y_in(sentiment_per_urgency_plot)
}

sentiment_per_urgency_plot

```


Hoch dringliche Nachrichten enthalten h√§ufiger negativ formulierte Texte, etwa bei Problemen oder St√∂rungen. Weniger dringliche Anfragen sind oft neutral oder positiv, z.B. bei allgemeinen R√ºckfragen oder W√ºnschen. Die Stimmung im Text kann also ein guter Hinweis auf die Dringlichkeit sein.


### Klassifikation 

Unser finaler Datensatz besteht aus einigen Merkmalen, die nun f√ºr das trainieren eines Modelles genutzt werden k√∂nnen, um damit zuk√ºnftige Nachrichten anhand des Textes in "dringend" oder "weniger dringend" zu klassifizieren. 


```{r}
support_model_data <- support_summary |>
  select(
    Dringlichkeit,
    Nachricht,
    Bereich,
    Sentimentwert,
    Wortanzahl,
    Wortl√§nge,
    Frage,
    `Betreff vorhanden`,
    `Zeichenanzahl`,
    `Anzahl Ausrufezeichen`
  ) |>
  drop_na() |>
  mutate(across(c(Dringlichkeit, Bereich, Frage, `Betreff vorhanden`), factor))


tibble(
  Variable = names(support_model_data),
  Typ = map_chr(support_model_data, ~ class(.x)[1]),
  Beispiel = map_chr(support_model_data, ~ as.character(.x[1]))
) |>
  gt() |>
  tab_caption("Variablenbeschreibung des Modell-Datensatzes") |>
  cols_label(
    Variable = "Variable",
    Typ = "Datentyp",
    Beispiel = "Beispielwert"
  ) |>
  tab_options(
    table.width = pct(100),
    table.font.size = px(13),
    data_row.padding = px(4),
    ihtml.use_pagination = FALSE
  ) |>
  nd.util::nd_gt_tab_options() |>
  nd.util::nd_gt_to_html()

```


Um herauszufinden, ob eine Nachricht dringend ist oder nicht, wurde ein **maschinelles Lernmodell (Random Forest)** trainiert. Dabei wurden nicht nur der Inhalt der Nachricht, sondern auch sprachliche Merkmale wie Wortl√§nge, Anzahl an Ausrufezeichen, das Sentiment oder das Vorhandensein eines Betreffs ber√ºcksichtigt.

Das Modell wurde mit 75% der Daten trainiert und auf den verbleibenden 25% getestet. Die folgenden Schritte kamen dabei zum Einsatz:

{{{< fa-ul >}}}
{{{< fa-solid-li icon="broom" >}}} **Textvorverarbeitung:** Die Nachrichten wurden in einzelne W√∂rter zerlegt, Stoppw√∂rter entfernt und sogenannte TF-IDF-Werte berechnet.{{{< /fa-solid-li >}}}

{{{< fa-solid-li icon="wrench" >}}} **Merkmalsgenerierung:** Wir haben verschiedene Merkmale extrahiert ‚Äì darunter Sentimentwerte, Satzzeichenanzahl, Wortl√§nge oder auch das Vorhandensein eines Betreffs.{{{< /fa-solid-li >}}}

{{{< fa-solid-li icon="network-wired" >}}} **Klassifikation:** Anschlie√üend wurde ein Random-Forest-Modell trainiert, das Nachrichten automatisch in hohe oder geringe Dringlichkeit einordnet.{{{< /fa-solid-li >}}}

{{{< fa-solid-li icon="chart-line" >}}} **Modellbewertung:** Um die Qualit√§t des Modells zu beurteilen, wurden die Genauigkeit des Modells berechnet und anhand einer Konfusionsmatrix visualisiert. {{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}




```{r}
# TODO: Build nice classfier for urgency labels

#
# # Set seed for reproducibility
# set.seed(123)
# data_split <- initial_split(support_model_data, prop = 0.75, strata = urgency)
# train_data <- training(data_split)
# test_data  <- testing(data_split)
#
#
# # Recipe with TF-IDF and engineered features
# support_recipe <- recipe(urgency ~ message + sentiment_score +
#                          avg_word_length + contains_question + has_subject + queue + n_chars,
#                          data = train_data) |>
#   step_tokenize(message) |>
#   step_tokenfilter(message, max_tokens = 2000) |>
#   step_stopwords(message, language = "de") |>
#   step_tfidf(message) |>
#   step_dummy(all_nominal_predictors()) |>
#   step_zv(all_predictors()) |>
#   step_normalize(all_numeric_predictors()) |>
#   themis::step_downsample(urgency)
#
#
#
# ###### random forest
#
# tune_spec <- rand_forest(mtry = tune(), trees = 250, min_n = tune()) |>
#   set_mode("classification") |>
#   set_engine("ranger")
#
# tune_workflow <- workflow() |>
#   add_recipe(support_recipe) |>
#   add_model(tune_spec)
#
# res <- tune_grid(
#   tune_workflow,
#   resamples = vfold_cv(train_data, v = 5, strata = urgency),
#   grid = 5,
#   metrics = metric_set(accuracy, bal_accuracy, f_meas)
# )
#
#
# collect_metrics(res)
#
# best_params <- select_best(res, metric = c("f_meas"))
#
#
#
# final_rf_workflow <- finalize_workflow(tune_workflow, best_params)
#
# final_rf_fit <- fit(final_rf_workflow, data = train_data)

# saveRDS(final_rf_fit, "data/final_rf_model.rds")

final_rf_fit <- readRDS(fs::path(data_dir, "final_rf_model.rds"))

# final_preds <- predict(final_rf_fit, test_data, type = "class") |>
#   bind_cols(test_data)

# final_preds |>
#   select(urgency, .pred_class) |>
#   write.csv("data/final_predictions.csv", row.names = FALSE)

final_preds <- read.csv(fs::path(data_dir, "final_predictions.csv")) |>
  mutate(urgency = factor(urgency), .pred_class = factor(.pred_class))


# performance metrics
metriken <- final_preds |>
  yardstick::accuracy(truth = urgency, estimate = .pred_class) |>
  select(.metric, .estimate) |>
  mutate(
    .metric = recode(.metric, "accuracy" = "Genauigkeit"),
    .estimate = round(.estimate, 3)
  )

metriken |>
  gt() |>
  tab_caption(
    "Bewertung des Klassifikationsmodells"
  ) |>
  cols_label(
    .metric = "Metrik",
    .estimate = "Wert"
  ) |>
  fmt_percent(
    columns = ".estimate",
    scale_values = TRUE,
    decimals = 1
  ) |>
  tab_options(
    table.width = pct(60),
    table.font.size = px(14),
    data_row.padding = px(4)
  ) |>
  nd.util::nd_gt_tab_options() |>
  nd.util::nd_gt_to_html()
```

Das trainierte Klassifikationsmodell erzielt eine Genauigkeit von 97,9% auf den Testdaten. Dies bedeutet, dass nahezu alle Nachrichten korrekt als "hoch" oder "gering" dringlich eingestuft wurden.

Die Konfusionsmatrix visualisiert diese Leistung im Detail:

{{{< fa-ul >}}}
{{{< fa-solid-li icon="thumbs-up" >}}}Das Modell erkennt den Gro√üteil der Nachrichten korrekt: 1254 hoch dringliche und 916 gering dringliche Anfragen wurden richtig klassifiziert.{{{< /fa-solid-li >}}}

{{{< fa-solid-li icon="thumbs-down" >}}}Fehlklassifikationen traten nur in 23 F√§llen pro Klasse auf.{{{< /fa-solid-li >}}}
{{{< /fa-ul >}}}


```{r}
#| fig-height: 1.924034

conf_df <- final_preds |>
  yardstick::conf_mat(truth = urgency, estimate = .pred_class) |>
  tidy() |>
  mutate(
    truth = rep(c("Hoch", "Gering"), each = 2) |> factor(),
    prediction = rep(c("Hoch", "Gering"), times = 2) |> factor(),
    richtig = name %in% c("cell_1_1", "cell_2_2")
  )

conf_plot <-
  ggplot(conf_df, aes(x = prediction |> fct_rev(), y = truth, fill = richtig)) +
  geom_tile(color = "white", width = 0.9, height = 0.9) +
  geom_text(aes(label = value), size = 6, fontface = "bold", color = "white") +
  labs(
    x = "Vorhergesagt",
    y = "Tats√§chlich",
    fill = NULL
  ) +
  scale_fill_manual(values = c("TRUE" = "#39b185", "FALSE" = "#cf597e")) +
  theme(legend.position = "none")

if (interactive()) {
  5 * 0.25 + calc_panel_margin_y_in(conf_plot)
}

conf_plot
```


Damit das Modell im Alltag akzeptiert wird, ist es wichtig, seine **Entscheidungsgrundlagen transparent und nachvollziehbar darzustellen**. Wenn Mitarbeitende erkennen k√∂nnen, warum ein Ticket als dringend eingestuft wurde, k√∂nnte die Bereitschaft steigen, die Empfehlungen des Systems als sinnvolle Unterst√ºtzung zu nutzen.

Um diese Transparenz zu schaffen, haben wir die **zentralen Textmerkmale** aus dem Random-Forest-Modell extrahiert und direkt in den Originalnachrichten hervorgehoben.


```{r}

# library(vip)
# vip::vi(final_rf_fit) |>
#   filter(str_detect(Variable, "^tfidf_Nachricht_")) |>
#   mutate(
#     token = str_remove(Variable, "^tfidf_Nachricht_"),
#     token = str_replace_all(token, "_", " ")
#   ) |>
#   arrange(desc(Importance)) |>
#   readr::write_csv("data/importance_rf.csv")

importance_data <- readr::read_csv(fs::path(data_dir, "importance_rf.csv"))

urgency_cues_rf <- importance_data |>
  slice_head(n = 150) |>        
  pull(token) |>
  unique()

neg_lex <- vns.data::sentiws_tbl |>
  filter(tok_pol_num < 0) |>
  pull(tok_str) |>
  unique() |>
  tolower()

highlight_ticket_rf <- function(text, urgency_terms, negative_terms) {
  toks <- stringr::str_split(text, "(?<=\\b)|(?=\\b)")[[1]] 
  out <- vapply(toks, function(tok) {
    clean <- stringr::str_to_lower(stringr::str_replace_all(tok, "[^\\p{L}\\p{N}]+", ""))
    is_urg <- clean %in% urgency_terms
    is_neg <- clean %in% negative_terms

    if (is_urg && is_neg) {
      sprintf("<b><span style='color:#cf597e'>%s</span></b>", htmlEscape(tok))
    } else if (is_urg) {
      sprintf("<b>%s</b>", htmlEscape(tok))
    } else if (is_neg) {
      sprintf("<span style='color:#cf597e'>%s</span>", htmlEscape(tok))
    } else {
      htmlEscape(tok)
    }
  }, character(1))
  HTML(paste0(out, collapse = ""))
}


set.seed(42)
n_hoch   <- 10
n_gering <- 10


examples <- bind_rows(
  support |> filter(Dringlichkeit == "hoch")   |> slice_sample(n = n_hoch),
  support |> filter(Dringlichkeit == "gering") |> slice_sample(n = n_gering)
) |>
  mutate(
    Dringlichkeit = as.character(Dringlichkeit),
    Betreff = ifelse(is.na(Betreff) | str_trim(Betreff) == "", "(ohne Betreff)", Betreff),
    Nachricht = str_replace_all(Nachricht, "\\\\n", " "),
    Nachricht = str_replace_all(Nachricht, "\n", " "),
    Nachricht = str_replace_all(Nachricht, "<br\\s*/?>", " "),
    Nachricht = str_squish(Nachricht),
    Nachricht_annot = map(Nachricht, ~ highlight_ticket_rf(.x, urgency_cues_rf, neg_lex))
  ) |>
  slice_sample(n = n_hoch + n_gering)  

legend_html <- tags$div(
  tags$span("Legende: "),
  tags$span(style="font-weight:600;", "Fett"), " = RF-Signal (wichtiges Token); ",
  tags$span(style="color:#cf597e;", "Rot"), " = negatives Sentiment; ",
  tags$span(style="font-weight:600;color:#cf597e;", "Fett + Rot"), " = beides"
)

card_items <- pmap(
  list(examples$Betreff, examples$Nachricht_annot, examples$Bereich, examples$Dringlichkeit),
  function(betreff, nachricht_html, bereich, dring) {

    badge_col <- if (tolower(dring) == "hoch") "#cf597e" else "#39b185"

    tags$div(
      class = "card", style = "width: 100%;",
      tags$ul(
        class = "list-group list-group-flush",

        tags$li(class = "list-group-item",
                tags$code("Betreff: "), betreff),

        tags$li(class = "list-group-item",
                tags$code("Bereich: "), bereich),

        tags$li(class = "list-group-item",
                tags$code("Dringlichkeit: "),
                tags$span(class = "badge",
                          style = paste0("background-color:", badge_col, ";"),
                          dring)
        ),

        tags$li(class = "list-group-item",
                tags$code("Legende: "), legend_html),

        tags$li(
          class = "list-group-item",
          tags$code("Nachricht:"),
          tags$div(
            style = paste(
              "overflow: hidden; width: 100%; display: -webkit-box;",
              "-webkit-line-clamp: 8; -webkit-box-orient: vertical; font-size: 0.95rem;"
            ),
            nachricht_html
          )
        )
      )
    )
  }
)

nd.util::nd_carousel(card_items, .title = "Dringlichkeits-Hinweise des Klassifikationsmodells")

```


Damit wird sichtbar, dass das Modell z. B. bei Formulierungen wie ‚ÄûFehler‚Äú, ‚ÄûProblem‚Äú oder ‚ÄûSchwierigkeiten‚Äú eher zu einer hohen Dringlichkeit tendiert. Tickets mit neutraleren oder allgemeineren Formulierungen landen dagegen h√§ufiger in der gering dringlich-Kategorie.


### Fazit

In dieser Fallstudie haben wir gezeigt, wie sich Support-Tickets allein anhand der Nachricht automatisiert nach Dringlichkeit klassifizieren lassen. Schon **einfache sprachliche Merkmale** wie Wortwahl, Fragen oder Stimmung liefern ausreichend Informationen, um ein leistungsf√§higes Modell zu trainieren. Dadurch k√∂nnen Unternehmen **kritische Anliegen schneller identifizieren**, **Bearbeitungszeiten verk√ºrzen** und die **Kundenzufriedenheit gezielt steigern**. Zudem schafft die Hervorhebung wichtiger Textsignale **Transparenz** und erleichtert die **Akzeptanz** solcher Systeme im Arbeitsalltag.

